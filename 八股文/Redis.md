# 1. Redis常用的数据结构
- String：简单动态字符串
- List：双向链表
- Set：HashSet
- Hash：HashMap
- ZSet：类似Set，加了一个权重参数score，使元素能按照score排序，数据量较大时同时使用skiplist和hashtable实现

# ZSet中的跳表
当 ZSet 中的元素数量较多，或者元素成员（member）是比较长的字符串时，Redis 就会采用跳表作为其底层实现之一。为了弥补跳表在按成员查找分数（`ZSCORE` 命令）上的低效，Redis 实际上是**同时使用了跳表和哈希表**来共同实现 ZSet。

-   **跳表（Skiplist）**：用于按分数（score）进行高效的范围查找和排序。
    
-   **哈希表（Hashtable）**：用于以 O(1) 的时间复杂度根据成员（member）查找其对应的分数。
    

两者通过指针互相关联，保证了数据的一致性。

### 什么是跳表？

跳表是一种**概率性数据结构**，可以看作是对有序链表的优化。它通过在原始链表的基础上增加多级“快速通道”（索引层），来实现类似二分查找的高效查找性能。

想象一下一个普通的有序链表，要查找一个元素，你必须从头到尾逐个遍历，时间复杂度是 O(N)。

_（这是一个普通的有序链表）_

现在，我们从这个链表中每隔一个元素，就提取出来，并增加一个指向上层节点的指针，这就构成了一个新的“索引”层。

_（这是一个包含多级索引的跳表）_

**查找过程**：

1.  从最高层的索引开始查找。
    
2.  在当前层，向右移动，直到找到一个大于或等于目标值的节点，或者到达当前层的末尾。
    
3.  如果找到了大于目标值的节点，就从前一个节点**下降一层**，重复步骤 2。
    
4.  最终，在最底层（原始链表层）找到目标元素或确定其不存在。
    

通过这种方式，跳表可以跳过大量节点，其平均查找、插入和删除的时间复杂度都是 **O(logN)**，与平衡树（如红黑树）相当，但实现起来却简单得多。

----------

### Redis 中的跳表实现

Redis 的跳表设计非常精巧，我们来看一下它的具体结构。

#### 1. 跳表节点 (zskiplistNode)

每个跳表节点都包含以下关键部分：

-   **`ele` (element)**: 存储的成员（member）值。
    
-   **`score` (分数)**: 该成员对应的分数，用于排序。
    
-   **`backward` (后退指针)**: 指向其在原始链表中的前一个节点。这使得跳表可以从后向前遍历。
    
-   **`level[]` (层级数组)**: 这是跳表的核心。每个节点都包含一个层级数组，数组的每个元素 (`zskiplistLevel`) 都包含：
    
    -   **`forward` (前进指针)**: 指向同一层级的下一个节点。
        
    -   **`span` (跨度)**: 记录当前节点的前进指针指向下一个节点之间，跨越了多少个节点。这个“跨度”是计算排名（`ZRANK` 命令）的关键。
        

#### 2. 跳表结构 (zskiplist)

整个跳表由一个 `zskiplist` 结构来管理，它包含：

-   **`header` (头节点)**: 一个不存储任何实际数据的头节点，其层级数组包含指向各层级第一个节点的指针。
    
-   **`tail` (尾节点)**: 指向跳表的最后一个节点，方便在表尾进行操作。
    
-   **`length` (长度)**: 记录跳表中节点的总数量（不包括头节点）。
    
-   **`level` (层级)**: 记录当前跳表的最大层级数。
    

下图是 Redis 跳表一个节点的简化示意图：

```
+----------------+
| ele (member)   |
| score          |
+----------------+
| *backward      |
+----------------+
| level[0]       | --> forward, span
+----------------+
| level[1]       | --> forward, span
+----------------+
| ...            |
+----------------+
| level[n]       | --> forward, span
+----------------+
```

#### 3. 随机的层级

跳表的一个有趣之处在于，新节点被插入时，它的层级数是**随机**决定的。Redis 的策略是：

-   每个节点至少有 1 层（即原始链表层）。
    
-   之后，以 25% 的概率增加一层，直到达到最大层级限制（Redis 中是 32 层）或者随机过程停止。
    

这种随机性使得跳表的结构在动态增删下，能够大概率保持平衡，从而保证 O(logN) 的性能。

#### 4. `span` (跨度) 的作用

`span` 是 Redis 跳表实现中的一个亮点。它记录了从当前节点的某一层级，到该层级下一个节点之间，有多少个底层节点。

在上图中，从头节点（header）的 L2 层到节点 7，`span` 是 2，因为中间跨越了 2 个节点（节点 1 和节点 3）。

**有了 `span`，计算一个成员的排名就变得非常高效**：

1.  在查找该成员的路径上，将经过的所有前进指针的 `span` 值累加起来。
    
2.  最终得到的总和，就是该成员在有序集合中的排名。
    

这使得 `ZRANK` (获取排名) 命令的时间复杂度也保持在 O(logN)。

# 2. Redis单线程模型了解吗
对于读写命令，在 Redis 4.0 版本之后引入了多线程来执行一些大键值对的异步删除操作，Redis 6.0 版本之后引入了多线程来处理网络请求（提高网络 IO 读写性能）

# 3. 单线程如何监听大量的客户端连接
通过IO多路复用，I/O 多路复用技术的使用让 Redis 不需要额外创建多余的线程来监听客户端的大量连接，降低了资源的消耗

# 4. Redis为何给缓存数据设定过期时间，如何判断是否过期，过期数据删除策略？
1. 缓存大小有限，短信验证码之类的功能也要设定过期时间
2. 通过一个过期字典（hash表）保存过期时间
3. redis采用定期删除（周期性地随机从设置了过期时间的 key 中抽查一批，然后逐个检查这些 key 是否过期）+ 惰性删除（只会在取出/查询 key 的时候才对数据进行过期检查）

# 5. Redis内存淘汰策略
六种
volatile/allkeys * lru/ttl/random

后续加入lfu

# 6. RDB持久化
Redis通过创建snapshot来获得存储在内存里面的数据在某个时间点上的副本

# 7. AOF持久化
每执行一条更改Redis中的数据的命令，Redis将该命令写入到内存缓存`server.aof_buf`中，再更具`appendfsync`配置决定什么时候同步到硬盘中的AOF文件

### 二、 RDB 快照 (Snapshotting)

#### 1. 工作原理

RDB 是 Redis **默认**的持久化方式。它会在满足特定条件时，将内存中的**所有数据**生成一个经过压缩的二进制快照文件，通常命名为 `dump.rdb`。

**触发 RDB 的方式：**

-   **自动触发**：在 `redis.conf` 文件中通过 `save` 配置来触发。
    
    代码段
    
    ```
    # 格式: save <seconds> <changes>
    # 表示在 900 秒内，如果至少有 1 个 key 发生了改变，就自动触发 RDB
    save 900 1
    # 表示在 300 秒内，如果至少有 10 个 key 发生了改变，就自动触发 RDB
    save 300 10
    ```
    
-   **手动触发**：
    
    -   `SAVE` 命令：会**阻塞** Redis 主进程，直到 RDB 文件创建完毕。在此期间，Redis 不能处理任何其他命令。**（生产环境禁用）**
        
    -   `BGSAVE` 命令：Redis 会在后台**异步**进行快照操作。它会 `fork()` 一个子进程，由子进程负责将快照写入磁盘，而主进程可以继续处理客户端请求。**（推荐使用）**
        

#### 2. 优点

-   **性能好，恢复快**：RDB 文件是一个紧凑的二进制文件，里面存储的是某个时间点的数据本身。在恢复数据时，Redis 只需要直接读取并加载这个文件到内存中即可，速度非常快，特别适合做冷备份和灾难恢复。
    
-   **文件体积小**：经过压缩，文件体积比 AOF 小得多。
    
-   **对主进程性能影响小**：使用 `BGSAVE` 时，主进程只需 `fork()` 操作（这个操作很快），之后的数据写入完全由子进程负责，对主进程的阻塞时间极短。
    

#### 3. 缺点

-   **数据丢失风险高**：RDB 采用间隔性保存的策略。如果 Redis 在两次快照之间发生故障，那么从上一次快照到故障发生这段时间内的所有数据都将**全部丢失**。这个间隔可能是一分钟，也可能是几分钟。
    
-   **`fork()` 的成本**：虽然 `fork()` 很快，但在数据量巨大的情况下，它依然会消耗一定的内存和 CPU 资源，可能导致 Redis 服务出现短暂的卡顿。
    

----------

### 三、 AOF 日志 (Append Only File)

#### 1. 工作原理

AOF 记录的是 Redis 服务器接收到的**每一条写命令**（如 `SET`, `INCR`）。这些命令以文本格式被追加到 AOF 文件的末尾。当 Redis 重启时，它会**重新执行** AOF 文件中的所有命令，从而恢复数据。

**AOF 的写回策略 (`appendfsync`)：** 为了平衡性能和数据安全，AOF 提供了三种将日志刷入磁盘的策略：

-   `always`：**每条**写命令都立刻同步到磁盘。**最安全，但性能最差**，因为磁盘 I/O 非常频繁。
    
-   `everysec`：**每秒钟**将缓存区的命令同步到磁盘一次。这是**默认和推荐**的配置，在性能和数据安全之间取得了很好的平衡。即使发生故障，最多也只会丢失 1 秒钟的数据。
    
-   `no`：完全由操作系统来决定什么时候同步。**最快，但最不安全**。
    

#### 2. AOF 重写 (Rewrite)

随着时间推移，AOF 文件会越来越大，因为它记录了所有的历史操作（比如对一个计数器 `INCR` 100次，AOF 里就有100条记录）。为了解决这个问题，Redis 引入了 **AOF 重写**机制。

-   **原理**：AOF 重写**并不是**去读取和分析旧的 AOF 文件，而是直接从当前数据库的内存中读取**最终的数据状态**，然后用一条条最精简的命令来生成一个新的、更小的 AOF 文件。
    
    -   例如，上面那个被 `INCR` 了100次的计数器，其最终值为 100。在新的 AOF 文件里，就只会有一条命令：`SET counter 100`。
        
-   **触发**：可以通过 `BGREWRITEAOF` 命令手动触发，也可以配置自动触发。这个过程也是在后台异步执行的。
    

#### 3. 优点

-   **数据安全性高**：使用 `everysec` 策略时，最多只会丢失 1 秒的数据，比 RDB 的分钟级丢失要安全得多。
    
-   **日志可读**：AOF 文件是文本格式，可以很方便地阅读和分析。如果不小心执行了 `FLUSHALL` 命令，只要 AOF 文件还没有被重写，我们甚至可以手动编辑 AOF 文件，删除最后那条 `FLUSHALL` 命令，然后重启 Redis 来恢复数据。
    

#### 4. 缺点

-   **文件体积大**：通常情况下，AOF 文件的大小会比 RDB 文件大。
    
-   **恢复速度慢**：数据恢复时需要重新执行所有写命令，当 AOF 文件很大时，恢复过程会比 RDB 慢很多。
    
-   **写入性能有一定影响**：即使是 `everysec` 策略，每秒一次的磁盘同步也会对 Redis 的 QPS 产生一定的影响。
    

#### **最佳实践：混合持久化 (RDB + AOF)**

从 Redis 4.0 开始，引入了**混合持久化**的模式，这可以说是结合了 RDB 和 AOF 两者的优点。

-   **如何工作**：当开启混合持久化后，在进行 AOF 重写时，Redis 不再是单纯地生成命令，而是会 `fork` 一个子进程，将当前内存中的数据以 **RDB 的格式**写入到新的 AOF 文件的开头，然后再将重写期间产生的**增量写命令**追加到文件末尾。
    
-   **恢复时**：
    
    1.  Redis 先加载文件开头的 RDB 部分，快速恢复大部分数据。
        
    2.  然后再加载文件末尾的 AOF 增量命令部分，恢复最新的数据。
        
-   **优点**：既保证了 AOF 的高数据安全性，又利用了 RDB 的快速恢复能力。


# 8. 如何使用Redis事务
通过MULTI, EXEC, DISCARD, WATCH等关键字

# 9. Redis事务支持原子性嘛
不支持，事务运行错误的情况下，只有错误的指令不会被执行，且Redis不支持回滚

# 10. 如何解决Redis事务的缺陷
Redis 从 2.6 版本开始支持执行 Lua 脚本，它的功能和事务非常类似。我们可以利用 Lua 脚本来批量执行多条 Redis 命令，这些 Redis 命令会被提交到 Redis 服务器一次性执行完成，大幅减小了网络开销。

一段 Lua 脚本可以视作一条命令执行，一段 Lua 脚本执行过程中不会有其他脚本或 Redis 命令同时执行，保证了操作不会被其他指令插入或打扰。

不过，如果 Lua 脚本运行时出错并中途结束，出错之后的命令是不会被执行的。并且，出错之前执行的命令是无法被撤销的，无法实现类似关系型数据库执行失败可以回滚的那种原子性效果。因此，**严格来说的话，通过 Lua 脚本来批量执行 Redis 命令实际也是不完全满足原子性的。**


# 11. 什么是Big Key/Hot Key/
一个key对应的value占用的内存比较大/一个 key 的访问次数比较多且明显多于其他 key
处理方案
- 分割bigkey，手动清理，采用合适的数据结构，开启lazy-free
- 读写分离，使用Redis Cluster，二级缓存

# 12. 如何避免大量key集中过期
给key设置随机过期时间+开启lazy-free

# 13. Redis内存碎片
产生原因：
**Redis 存储数据的时候向操作系统申请的内存空间可能会大于数据实际需要的存储空间。**
**频繁修改 Redis 中的数据也会产生内存碎片。**

# 14. 缓存穿透
大量请求的key不在缓存中，也不再数据库中	
解决：
- 缓存无效key：查到某个key不在数据库中，将其存入缓存
- 布隆过滤器

# 利用布隆过滤器防止缓存穿透，如果此时我更新了数据库，更新后数据如何同步到布隆过滤器中
标准布隆过滤器（Standard Bloom Filter）的一个关键特性：**它不支持删除或更新操作**。
布隆过滤器的核心是一个位数组（bit array）和多个哈希函数。添加一个元素时，会用多个哈希函数计算出几个位置，并将位数组中这些位置的 bit 设置为 1。

当你尝试删除一个元素时，你可能会想把这些位置的 bit 重新设置为 0。但问题在于，**这些 bit 位可能被其他元素共享**。如果你强行设置为 0，就会导致其他本应存在的元素被“误删”，从而产生**错误否定（False Negative）**，这是布隆过滤器绝对不能容忍的（它可以容忍错误肯定，但不能容忍错误否定）。

1. 方案一：定期重建 (最常用、最简单)
2. 方案二：使用支持删除的布隆过滤器变种 ：计数布隆过滤器(Counting Bloom Filter)
-   **空间占用更大**：相比于只占 1 bit 的标准布隆过滤器，一个计数器需要 4 位、8 位或更多，导致内存消耗是前者的数倍。
    
-   实现更复杂，需要考虑计数器溢出等边界问题。
    
-   现成的、经过生产环境检验的库相对较少（例如，Google Guava 提供的 BloomFilter 就不是 Counting 类型的）。
3. 通过订阅 Binlog 进行实时同步 (架构复杂)

# 15. 缓存击穿
请求的 key 对应的是 **热点数据**，该数据 **存在于数据库中，但不存在于缓存中（通常是因为缓存中的那份数据已经过期）**。这就可能会导致瞬时大量的请求直接打到了数据库上

解决：
- 提前预热
- 加锁，设置互斥锁保证只有一个请求能查询数据库并更新缓存
- 热点Key永不过期
- 逻辑过期，缓存里不仅存数据，还存一个**过期时间戳**，查询时如果逻辑上未过期，直接返回；如果逻辑上过期，后台异步更新，但仍返回旧数据。

# 16. 缓存雪崩
**缓存在同一时间大面积的失效，导致大量的请求都直接落到了数据库上，对数据库造成了巨大的压力**

解决：
- Redis集群


# 17. 保证Redis服务高可用
Redis Sentinel集群
### 什么是Sentinel，作用？
哨兵是Redis的一种运行模式，监控所有redis节点，故障转移，通知，配置提供

### Sentinel如何检测节点是否下线
主观下线：单个sentinel认为下线；客观下线：过半sentinel认为下线
每个sentinel节点以固定频率向整个集群中的master和slave发送ping，如果发现master下线，开启故障转移

### 如何选举出新的master
slave优先级
复制进度：选出数据最完整的的slave
runid：前两项一样，选runid最小的

# 18. Redis Cluster
解决缓存的数据量太大和并发量太大的问题

通过部署多台Redis主节点，同时提供读写服务，缓存的数据库相对均匀地分布在这些主节点上，客户端的请求通过路由规则转发到目标master上

为保证高可用，每台master配备一多个slave

### Redis Cluster是如何分片的
采用哈希槽分区，每一个键值对都属于一个哈希槽

### 节点之间如何通信
Gossip协议
![输入图片说明](/imgs/2025-03-25/hy5BibOnmpqkvNzi.png)
### 二、 核心原理：哈希槽 (Hash Slot)

Redis Cluster 没有使用传统的一致性哈希算法，而是引入了一个叫做**哈希槽**的概念。这是它分片机制的基石。

1.  **固定的“投递区”**：
    
    -   Redis Cluster 预先设定了 **16384** 个哈希槽（编号从 0 到 16383）。这个数字是固定的，不会改变。
        
    -   你可以把这 16384 个槽想象成邮政系统里那 16384 个固定的“投递区”。
        
2.  **Key 到槽的映射规则**：
    
    -   当你要操作一个 Key（比如 `SET mykey "hello"`）时，Redis Cluster 会使用 CRC16 算法计算这个 Key 的一个数值，然后用这个数值对 16384 取模，得到的结果就是这个 Key 应该属于哪个槽。
        
    -   **公式**：`slot = CRC16(key) % 16384`
        
    -   这个计算过程是**确定性**的，意味着**同一个 Key 无论计算多少次，结果都会落入同一个固定的槽中**。就像同一栋楼的地址，永远属于同一个投递区。
        
3.  **槽到节点的分配**：
    
    -   当你搭建 Redis Cluster 时，你需要决定启动多少个主节点（Master）。
        
    -   Cluster 会将这 16384 个槽，**平均地分配**给这些主节点。
        
    -   例如，如果你有 3 个主节点 (Master A, B, C)，那么分配结果可能如下：
        
        -   **Master A** 负责槽：`0` - `5460`
            
        -   **Master B** 负责槽：`5461` - `10922`
            
        -   **Master C** 负责槽：`10923` - `16383`
            
    -   每个主节点只负责处理自己“辖区”内的数据。
        

----------

### 三、 工作流程：客户端如何找到正确的节点？

Redis Cluster 的客户端（比如 Jedis, Lettuce）都是“聪明”的客户端。它内部会缓存一份“**槽位分配表**”（Slot -> Node 的映射关系）。

**一个 `SET` 命令的完整旅程：**

1.  **客户端计算**：
    
    -   客户端收到命令 `SET user:1000:name "Alice"`。
        
    -   它首先在本地计算 `key` 的槽位：`slot = CRC16("user:1000:name") % 16384`。假设计算结果是 `7638`。
        
2.  **客户端查找路由**：
    
    -   客户端查询自己缓存的“槽位分配表”，发现槽 `7638` 是由 **Master B** 负责的。
        
3.  **直接通信**：
    
    -   客户端直接与 **Master B** 建立连接，并将 `SET` 命令发送给它。Master B 执行命令并返回结果。
        

**这个流程非常高效，因为客户端大多数时候都能直接找到正确的节点，避免了不必要的跳转。**

----------

### 四、 关键机制：重定向 (MOVED)

**问题**：如果集群的拓扑结构发生了变化（比如，为了扩容，我们将 Master B 的一部分槽迁移到了新的 Master D 上），而客户端的缓存还是旧的，会发生什么？

这就是**MOVED 重定向**机制发挥作用的时候。

1.  客户端根据旧的缓存，依然将 `key` (槽 `7638`) 的请求发送给了 **Master B**。
    
2.  Master B 收到请求后，发现槽 `7638` 已经不归自己管了，现在由 **Master D** 负责。
    
3.  Master B **不会**处理这个请求，而是会返回一个特殊的 `MOVED` 错误给客户端，这个错误包含了正确的信息：`MOVED 7638 192.168.1.104:6379` (Master D 的地址)。
    
4.  **客户端收到 `MOVED` 响应后**：
    
    -   它会**自动更新**自己内部的“槽位分配表”，记录下“槽 `7638` 现在归 Master D 管”。
        
    -   然后，它会**重新向正确的 Master D** 发送刚才的命令。
        
    -   下一次再有 `key` 属于槽 `7638`，客户端就能直接找到 Master D 了。
        

这个自动重定向和缓存更新的机制，使得 Redis Cluster 在进行**扩容**或**缩容**时，能够对客户端保持基本透明。
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTkyNDMxOTg5LDMzNzIwMjE0NCwtMjA5Mj
A0NzYxNCwtNDM4Njg5NDg0LDI4OTc4NTQyOCwtOTU0NjU2NDkz
LC0yMDg4NzQ2NjEyXX0=
-->