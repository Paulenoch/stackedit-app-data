# 消息队列的应用场景
- 异步处理，用户下单后即可返回结果，等数据库处理完成后再正式通知用户下单完成
- 削峰/限流：大量请求涌入的时候，先全部存放于消息队列中，避免直接把后端服务打垮掉
- 降低系统耦合度![输入图片说明](/imgs/2025-05-29/3wgp7kkU3X501wEY.png)
- 处理分布式事务：**服务A执行本地事务**，如扣款，并**发送一条“扣款成功”的消息到消息队列**（这个操作要保证与本地事务的原子性，比如本地消息表/事务消息等技术）。**服务B监听到消息后执行自己的本地事务**，如发货。如果**服务B处理失败，可以重试，或者通知服务A进行人工处理**。
- 保证数据按照特定的顺序被处理
- 延时/定时处理

# 引入消息队列可能会带来哪些问题
-   **系统可用性降低：** 系统可用性在某种程度上降低，为什么这样说呢？在加入 MQ 之前，你不用考虑消息丢失或者说 MQ 挂掉等等的情况，但是，引入 MQ 之后你就需要去考虑了！
-   **系统复杂性提高：** 加入 MQ 之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！
-   **一致性问题：** 我上面讲了消息队列可以实现异步，消息队列带来的异步确实可以提高系统响应速度。但是，万一消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了!

# Kafka
Kafka 是一个分布式流式处理平台。

流平台具有三个关键功能：

1.  **消息队列**：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。
2.  **容错的持久方式存储记录消息流**：Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险。
3.  **流式处理平台：** 在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。

### 相比其他MQ的优势
-   **极致的性能**：基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。
-   **生态系统兼容性无可匹敌**：Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域。

![输入图片说明](/imgs/2025-05-29/lbYVreMPacTGGZFU.png)
Kafka 将生产者发布的消息发送到 **Topic（主题）** 中，需要这些消息的消费者可以订阅这些 **Topic（主题）**
- **Broker（代理）** : 可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个 Kafka Cluster
-   **Topic（主题）** : Producer 将消息发送到特定的主题，Consumer 通过订阅特定的 Topic(主题) 来消费消息。
-   **Partition（分区）** : Partition 属于 Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上，这也就表明一个 Topic 可以横跨多个 Broker 。每个partition可以接收多个生产者的消息，每个 partition 在一个消费组内“同一时刻只会被一个消费者实例消费”，多个消费组可以并行消费同一个 partition

> 划重点：**Kafka 中的 Partition（分区） 实际上可以对应成为消息队列中的队列。

### Kafka的多副本机制
Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。

> 生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。当 leader 副本发生故障时会从 follower 中选举出一个 leader,但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选。

**Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？**

1.  Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。
2.  Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。

### Zookeeper在Kafka中起到什么作用
-   **Broker 注册**：在 Zookeeper 上会有一个专门**用来进行 Broker 服务器列表记录**的节点。每个 Broker 在启动时，都会到 Zookeeper 上进行注册，即到 `/brokers/ids` 下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去
-   **Topic 注册**：在 Kafka 中，同一个**Topic 的消息会被分成多个分区**并将其分布在多个 Broker 上，**这些分区信息及与 Broker 的对应关系**也都是由 Zookeeper 在维护。比如我创建了一个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些文件夹：`/brokers/topics/my-topic/Partitions/0`、`/brokers/topics/my-topic/Partitions/1`
-   **负载均衡**：上面也说过了 Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力。 对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。

### Kafka如何保证消息的有序性
**1. 同一Partition内有序**

-   Kafka **只能保证“同一个Partition内的消息是有序的”**。
    
-   具体来说，消息写入到同一个Partition时，Kafka会按照消息到达的顺序追加写入日志文件（append only）。
    
-   消费端也是按照消息在Partition内的顺序拉取数据。
    
-   这样就实现了**单Partition内的强有序**。
    

**2. 不同Partition之间不保证有序**

-   不同Partition之间的消息没有全局顺序，Kafka本身也不会做全局排序。

 **生产者如果想让某一类消息严格有序（比如同一个用户、订单、账号），应该让这些消息始终写入同一个Partition。**
    
-   这通常通过指定消息的Key（如用户ID、订单ID等），由Kafka对Key做hash，路由到固定Partition。
    
-   这样，同一个Key的数据就会落到同一个Partition，天然有序。
<!--stackedit_data:
eyJoaXN0b3J5IjpbMzM0MzgxMzQ0LC03NzAwMDcxODksMjA5Mj
EyNTQzNiwtOTY1MTcxNDMyLDExMjcxMjA1NzgsLTIwODg3NDY2
MTJdfQ==
-->