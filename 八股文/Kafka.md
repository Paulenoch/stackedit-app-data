# 消息队列的应用场景
- 异步处理，用户下单后即可返回结果，等数据库处理完成后再正式通知用户下单完成
- 削峰/限流：大量请求涌入的时候，先全部存放于消息队列中，避免直接把后端服务打垮掉
- 降低系统耦合度![输入图片说明](/imgs/2025-05-29/3wgp7kkU3X501wEY.png)
- 处理分布式事务：**服务A执行本地事务**，如扣款，并**发送一条“扣款成功”的消息到消息队列**（这个操作要保证与本地事务的原子性，比如本地消息表/事务消息等技术）。**服务B监听到消息后执行自己的本地事务**，如发货。如果**服务B处理失败，可以重试，或者通知服务A进行人工处理**。
- 保证数据按照特定的顺序被处理
- 延时/定时处理

# 引入消息队列可能会带来哪些问题
-   **系统可用性降低：** 系统可用性在某种程度上降低，为什么这样说呢？在加入 MQ 之前，你不用考虑消息丢失或者说 MQ 挂掉等等的情况，但是，引入 MQ 之后你就需要去考虑了！
-   **系统复杂性提高：** 加入 MQ 之后，你需要保证消息没有被重复消费、处理消息丢失的情况、保证消息传递的顺序性等等问题！
-   **一致性问题：** 我上面讲了消息队列可以实现异步，消息队列带来的异步确实可以提高系统响应速度。但是，万一消息的真正消费者并没有正确消费消息怎么办？这样就会导致数据不一致的情况了!

# Kafka
Kafka 是一个分布式流式处理平台。

流平台具有三个关键功能：

1.  **消息队列**：发布和订阅消息流，这个功能类似于消息队列，这也是 Kafka 也被归类为消息队列的原因。
2.  **容错的持久方式存储记录消息流**：Kafka 会把消息持久化到磁盘，有效避免了消息丢失的风险。
3.  **流式处理平台：** 在消息发布的时候进行处理，Kafka 提供了一个完整的流式处理类库。

### 相比其他MQ的优势
-   **极致的性能**：基于 Scala 和 Java 语言开发，设计中大量使用了批量处理和异步的思想，最高可以每秒处理千万级别的消息。
-   **生态系统兼容性无可匹敌**：Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域。

![输入图片说明](/imgs/2025-05-29/lbYVreMPacTGGZFU.png)
Kafka 将生产者发布的消息发送到 **Topic（主题）** 中，需要这些消息的消费者可以订阅这些 **Topic（主题）**
- **Broker（代理）** : 可以看作是一个独立的 Kafka 实例。多个 Kafka Broker 组成一个 Kafka Cluster
-   **Topic（主题）** : Producer 将消息发送到特定的主题，Consumer 通过订阅特定的 Topic(主题) 来消费消息。
-   **Partition（分区）** : Partition 属于 Topic 的一部分。一个 Topic 可以有多个 Partition ，并且同一 Topic 下的 Partition 可以分布在不同的 Broker 上，这也就表明一个 Topic 可以横跨多个 Broker 。每个partition可以接收多个生产者的消息，每个 partition 在一个消费组内“同一时刻只会被一个消费者实例消费”，多个消费组可以并行消费同一个 partition

> 划重点：**Kafka 中的 Partition（分区） 实际上可以对应成为消息队列中的队列。

### Kafka的多副本机制
Kafka 为分区（Partition）引入了多副本（Replica）机制。分区（Partition）中的多个副本之间会有一个叫做 leader 的家伙，其他副本称为 follower。我们发送的消息会被发送到 leader 副本，然后 follower 副本才能从 leader 副本中拉取消息进行同步。

> 生产者和消费者只与 leader 副本交互。你可以理解为其他副本只是 leader 副本的拷贝，它们的存在只是为了保证消息存储的安全性。当 leader 副本发生故障时会从 follower 中选举出一个 leader,但是 follower 中如果有和 leader 同步程度达不到要求的参加不了 leader 的竞选。

**Kafka 的多分区（Partition）以及多副本（Replica）机制有什么好处呢？**

1.  Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力（负载均衡）。
2.  Partition 可以指定对应的 Replica 数, 这也极大地提高了消息存储的安全性, 提高了容灾能力，不过也相应的增加了所需要的存储空间。

### Zookeeper在Kafka中起到什么作用
-   **Broker 注册**：在 Zookeeper 上会有一个专门**用来进行 Broker 服务器列表记录**的节点。每个 Broker 在启动时，都会到 Zookeeper 上进行注册，即到 `/brokers/ids` 下创建属于自己的节点。每个 Broker 就会将自己的 IP 地址和端口等信息记录到该节点中去
-   **Topic 注册**：在 Kafka 中，同一个**Topic 的消息会被分成多个分区**并将其分布在多个 Broker 上，**这些分区信息及与 Broker 的对应关系**也都是由 Zookeeper 在维护。比如我创建了一个名字为 my-topic 的主题并且它有两个分区，对应到 zookeeper 中会创建这些文件夹：`/brokers/topics/my-topic/Partitions/0`、`/brokers/topics/my-topic/Partitions/1`
-   **负载均衡**：上面也说过了 Kafka 通过给特定 Topic 指定多个 Partition, 而各个 Partition 可以分布在不同的 Broker 上, 这样便能提供比较好的并发能力。 对于同一个 Topic 的不同 Partition，Kafka 会尽力将这些 Partition 分布到不同的 Broker 服务器上。当生产者产生消息后也会尽量投递到不同 Broker 的 Partition 里面。当 Consumer 消费的时候，Zookeeper 可以根据当前的 Partition 数量以及 Consumer 数量来实现动态负载均衡。

### Kafka如何保证消息的有序性
**1. 同一Partition内有序**

-   Kafka **只能保证“同一个Partition内的消息是有序的”**。
    
-   具体来说，消息写入到同一个Partition时，Kafka会按照消息到达的顺序追加写入日志文件（append only）。
    
-   消费端也是按照消息在Partition内的顺序拉取数据。
    
-   这样就实现了**单Partition内的强有序**。
    

**2. 不同Partition之间不保证有序**

-   不同Partition之间的消息没有全局顺序，Kafka本身也不会做全局排序。

 **生产者如果想让某一类消息严格有序（比如同一个用户、订单、账号），应该让这些消息始终写入同一个Partition。**
    
-   这通常通过指定消息的Key（如用户ID、订单ID等），由Kafka对Key做hash，路由到固定Partition。
    
-   这样，同一个Key的数据就会落到同一个Partition，天然有序。

### Kafka如何保证消息不丢失
**生产端**
1. Producer确认机制（acks参数）

-   **acks=0**：Producer发完消息不等待Broker响应，性能高但消息可能丢。
    
-   **acks=1**：只要Leader Broker收到消息就返回成功，Follower可能没收到，Broker挂掉可能丢失。
    
-   **acks=all（或-1）**：Leader和所有ISR副本都收到消息才返回成功。**最安全，强烈推荐用！**
    

2. Producer端重试机制

-   设置`retries`参数，Producer如果写入失败会自动重试，避免因短暂网络问题导致消息丢失。
    
-   配合`enable.idempotence=true`可以实现“幂等”写入，避免重试时消息重复。

**Broker端**
1. Partition副本机制（replication）

-   每个Partition可以有多个副本（replication factor），分布在不同的Broker。
    
-   一旦Leader Broker挂了，会有其他Follower副本顶上，**消息不会丢**。
    

2. 写入磁盘机制（磁盘落盘）

-   Kafka消息先写入内存（页缓存），再刷到磁盘。默认参数`log.flush.interval.messages`、`log.flush.interval.ms`控制刷盘频率。
    
-   配置合理可以最大程度避免Broker宕机导致消息丢失。

**消费端**
1. 手动提交消费位移（offset）

-   Kafka默认是自动提交offset，但有丢消息风险。**推荐手动提交offset，确保消息被处理后才提交。**
    
-   方案：消费后处理业务逻辑，业务执行完再提交offset（如commitSync）。
    

2. 反复消费（At least once）

-   Kafka设计为“至少一次”交付，极端情况下同一条消息可能会被消费两次（所以要幂等处理），但不会出现丢失。

### 重试机制
正常消费多次失败后，**将消息写入“重试队列”或“死信队列”**，后台有定时任务或人工介入再次处理。
**死信队列（Dead Letter Queue，简称 DLQ）** 是消息中间件中的一种特殊队列。它主要用于处理无法被消费者正确处理的消息，通常是因为消息格式错误、处理失败、消费超时等情况导致的消息被"丢弃"或"死亡"的情况。当消息进入队列后，消费者会尝试处理它。如果处理失败，或者超过一定的重试次数仍无法被成功处理，消息可以发送到死信队列中，而不是被永久性地丢弃。在死信队列中，可以进一步分析、处理这些无法正常消费的消息，以便定位问题、修复错误，并采取适当的措施。

# Kafka为什么快
Kafka 的快，并非依赖于单一的“黑科技”，而是源于其一系列精妙的、贴近操作系统底层原理的设计。其核心哲学可以概括为：**将消息处理流程尽可能地简化和线性化，最大限度地利用顺序 I/O 和现代操作系统的特性。**

下面是 Kafka 快的几个关键原因，我会为你逐一详细解释：

### 1. 顺序磁盘 I/O (Sequential Disk I/O) - 最核心的原因

这是 Kafka 高性能的基石。我们通常认为磁盘读写很慢，但这种印象主要来自于**随机**读写。对于**顺序**读写，磁盘（无论是机械硬盘还是SSD）的速度都非常快，甚至可以逼近内存的性能。

-   **工作原理**：Kafka 将消息以追加（append-only）的方式写入分区日志文件中。这意味着每条新消息都被添加到文件的末尾。这种操作就是纯粹的顺序写入。
    
-   **读取也是顺序的**：消费者（Consumer）通过一个偏移量（offset）来记录自己消费到了哪里。当它拉取消息时，也是从上一个 offset 开始，连续地读取一块数据。这同样是顺序读取。
    
-   **优势**：避免了磁盘磁头需要频繁移动寻找数据（随机寻道）所带来的巨大时间开销。对于操作系统来说，顺序读写可以进行大量的预读（read-ahead）和后写（write-behind）优化，进一步提升性能。
    

> **可以这样理解**：
> 
> -   **随机读写**：就像在一本巨大的字典里，让你无规律地查找一个个单词，每次都要翻很多页。
>     
> -   **顺序读写**：就像让你从头到尾读一本小说，你可以一页一页地、不间断地往下读，速度自然飞快。
>     

### 2. 零拷贝 (Zero-Copy)

为了减少数据在内存中的冗余复制，Kafka 大量使用了操作系统的“零拷贝”技术（在 Linux 中通常通过 `sendfile` 系统调用实现）。

-   **传统的数据传输过程**：
    
    1.  数据从磁盘读入到**内核空间**的缓冲区（Page Cache）。
        
    2.  数据从内核空间复制到**用户空间**的应用程序缓冲区。
        
    3.  数据再从用户空间复制回**内核空间**的套接字缓冲区（Socket Buffer）。
        
    4.  最后从套接字缓冲区发送到网卡，传输出去。 这个过程涉及多次 CPU 拷贝和内核态/用户态的切换，非常耗费资源。
        
-   **Kafka 的零拷贝过程**：
    
    1.  数据从磁盘读入到**内核空间**的缓冲区（Page Cache）。
        
    2.  数据直接从**内核空间**的缓冲区发送到网卡。 数据完全不经过用户空间的应用程序，省去了两次拷贝和两次上下文切换。这极大地减少了 CPU 和内存的开销，让数据传输路径变得极短，效率极高。
        

### 3. 数据的批量处理 (Batching)

Kafka 在客户端（生产者和消费者）和 Broker 端都大量使用了批量处理的思路，以此来摊平网络和磁盘 I/O 的开销。

-   **生产者 (Producer)**：并不会每条消息都立刻发送。它会先将消息缓存起来，凑成一个“批次”（batch），然后一次性地将整个批次发送给 Broker。
    
-   **消费者 (Consumer)**：也不是一条一条地去拉取消息。它会一次性地请求拉取一个数据块（比如 1MB），然后自己在内存中处理。
    

**优势**：将多次小的网络请求合并为一次大的网络请求，极大地减少了网络往返（Round-Trip）的开销，提高了网络利用率和整体吞吐量。这就像你一次性搬运一箱苹果，肯定比一次只拿一个、来回跑很多趟要快得多。

### 4. 分区并行处理 (Parallelism through Partitioning)

Kafka 的主题（Topic）可以被分为多个分区（Partition）。这些分区是实现其高并发和水平扩展能力的关键。

-   **并行写入**：生产者可以同时向一个 Topic 的不同分区发送消息。
    
-   **并行消费**：一个消费者组（Consumer Group）可以有多个消费者实例，每个实例负责消费一个或多个分区。
    
-   **水平扩展**：分区可以分布在集群中的不同服务器（Broker）上。当数据量增大时，你只需要增加服务器节点和分区数量，就可以线性地提升整个集群的处理能力。
    

每个分区都是一个独立的、有序的日志单元，这种设计将一个大的数据流拆分成了多个可以并行处理的小数据流，从而实现了惊人的并发处理能力。

### 5. 高效的数据压缩 (Efficient Data Compression)

Kafka 允许生产者在发送消息前对数据进行压缩。常见的压缩算法如 Snappy、Gzip、LZ4 都被支持。

-   **工作流程**：消息在生产者端被压缩成一个批次，然后以压缩后的形态发送到 Broker 并存储在磁盘上。消费者拉取到数据后，再在客户端进行解压缩。
    
-   **优势**：
    
    -   **减少网络I/O**：显著降低了网络传输的数据量，对于带宽敏感的环境尤为重要。
        
    -   **减少磁盘I/O**：减少了存储在磁盘上的数据大小。 在很多场景下，CPU 的压缩/解压缩开销远小于网络和磁盘 I/O 的开销，因此通过压缩换取更高的吞吐量是非常划算的。
<!--stackedit_data:
eyJoaXN0b3J5IjpbMTQ1NTE2MDczNSw4NDc4NDQ2MjddfQ==
-->